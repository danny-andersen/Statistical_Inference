---
title: "An investigation of the exponential distribution"
author: "Danny Andersen"
date: "17 October 2015"
output: pdf_document
keep_md: true
---
```{r libraries,warning=FALSE, message=FALSE ,echo = FALSE}
library(ggplot2)
```
## Overview

The R stats library contains a number of statistical distributions. This paper investigates the characteristics of the exponential distribution, whose probability density function is given by:  
$$
f(x) = \lambda {e}^{- \lambda x}  
$$  
for $x \geq 0$.  

The intent of this paper is to show for the exponential distribution that the sample mean and variance is equivalent to the population mean and variance. It will also show that it obeys the Central Limit Theorem (CLT) that states the mean and variance of a sample mean will be approximately normally distributed.

## Simulations

If we take a random sample of 40 values from an exponential population, the mean and variance of this sample set will be a random approximation of the true mean and variance of an exponential population.  

Therefore if we repeat this simulation 1000 times, we should find the mean of all of the sample means to be very close to the theoretical mean of $1/\lambda$ and the variance very close to the theoretical variance of ${1/\lambda}^{2}$. The R code below shows how the simulations are created. Note that the random seed is set to ensure repeatability of these results.   

```{r simulations}
means <- NULL
vars <- NULL
nosim <- 1000
n <- 40
lambda <- 0.2
set.seed(1234)
#Run 1000 simulations of 40 samples, taking the mean of each one
for (i in 1:nosim) {
    sample <- rexp(n, lambda)
    means <- c(means, mean(sample))
    vars <- c(vars, var(sample))
}
```

## Sample mean vs Theoretical mean

From this simulated data, we can calculate the average of all of the sample means, which according to the Central Limit Theorem, should approximate to the theoretical mean of $1/\lambda$.

```{r means}
sampleMean <- mean(means)
mu <- 1/lambda
acc <- abs(sampleMean - mu)*100/mu
```

This gives us an overall sample mean of `r format(round(sampleMean, 2), nsmall=2)`, which is very close to the theoretical mean of `r mu`, i.e. within `r format(round(acc,2), nsmall=2)`% .  

The plot below shows a histogram of all the simulated 1000 sample means, with a red line showing the centre of the distribution, i.e. the mean.  

```{r meanplots,echo=FALSE}
#Plot sample means
qplot(means,geom="histogram", ylab = "Frequency", xlab="Sample means", binwidth=0.1) +
    labs(title="Histogram of sample means") +
    geom_vline(xintercept = sampleMean, colour="red")
```

The variance of the sample mean is ${\sigma}^2/n$, whose estimate is given by ${S}^2/n$. 
```{r meanvariance}
meanVar <- (1/lambda^2)/n
sampleMeanVar <- var(means)
accMeanVar <- abs(sampleMeanVar - meanVar)*100/sampleMeanVar
```

In the simulations above the variance of the sample mean should theoretically be `r format(round(meanVar,2), nsmall=2)`, whereas it was calculated to be `r format(round(sampleMeanVar,2), nsmall=2)`, which is within `r format(round(accMeanVar,2),nsmall=2)`% 

## Sample variance vs Theoretical variance

From this simulated data, we can also calculate the variance of all of the sample variances, which according to the Central Limit Theorem, should approximate to the theoretical variance of lambda.

```{r vars}
sampleVariance <- mean(vars)
sigmaSq <- (1/lambda)^2
accVar <- abs(sampleVariance - sigmaSq)*100/sigmaSq
```

This gives us an average sample variance of `r format(round(sampleVariance,2),nsmall=2)`, which is very close to the theoretical variance of `r sigmaSq`, i.e. within `r format(round(accVar,2),nsmall=2)`% . It is interesting to note that this is not as close as the sample mean is to the theoretical mean. 

## Comparison with the standard normal distribution

The central limit theorem states that the distribution of iid variables becomes that of a standard normal as the sample size increases. This can be shown by scaling the sample mean to that of a uniform distribution by substracting the population mean and dividing by the  standard deviation of the mean, i.e.

$$
\frac{\bar{X_n} - \mu}{\sigma/\sqrt{n}}
$$

If we do this for all of our generated sample means:

```{r scaled }
#Scale generated means
sigma <- sqrt(sigmaSq)
scaler <- function(x) { (x-mu)/(sigma/sqrt(n)) }
smeans <- vapply(means, FUN=scaler, FUN.VALUE=c(1))
scaled_mu <- mean(smeans)
scaled_sigma <- sd(smeans)
```

we obtain a scaled mean of `r format(round(scaled_mu,3), nsmall=3)` which is very close to the normal distribution mean of 0 and a standard deviation of `r format(round(scaled_sigma,3),nsmall=3)`, which is close to the expected value of 1.

If we plot the histogram of the scaled means and compare it with the uniform distribution (shown as the black line) we find that there is a good match:

```{r uniform_plots, echo=FALSE}
g<-ggplot(as.data.frame(smeans), aes(x=smeans)) 
g<- g + geom_histogram(alpha=0.4, binwidth=0.3, aes(y=..density..)) 
g<- g + stat_function(fun=dnorm, size=1)
g + labs(x="Sample mean", y="Density", title="Normalised sample means compared to the normal distribution")
```

This demonstrates that the distribution of sample means closely resembles that of a normal distribution, as per the Central limit theorem.
